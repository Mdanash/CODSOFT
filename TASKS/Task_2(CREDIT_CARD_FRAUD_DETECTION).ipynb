{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EslL45fHNLX7"
   },
   "source": [
    "# **CREDIT CARD FRAUD DETECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tM2yDjMdXq7X"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('fraudTrain-Copy1.csv')\n",
    "test_data = pd.read_csv('fraudTest-Copy1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'first', 'last', 'dob', 'trans_num', 'unix_time', 'street']\n",
    "X_train = train_data.drop(columns_to_drop + ['is_fraud'], axis=1)\n",
    "y_train = train_data['is_fraud']\n",
    "X_test = test_data.drop(columns_to_drop + ['is_fraud'], axis=1)\n",
    "y_test = test_data['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1pDrQwGj6fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data preview after removing irrelevant columns:\n",
      "                             merchant       category     amt gender  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97      F   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23      F   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11      M   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00      M   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      M   \n",
      "\n",
      "             city state    zip      lat      long  city_pop  \\\n",
      "0  Moravian Falls    NC  28654  36.0788  -81.1781      3495   \n",
      "1          Orient    WA  99160  48.8878 -118.2105       149   \n",
      "2      Malad City    ID  83252  42.1808 -112.2620      4154   \n",
      "3         Boulder    MT  59632  46.2306 -112.1138      1939   \n",
      "4        Doe Hill    VA  24433  38.4207  -79.4629        99   \n",
      "\n",
      "                                 job  merch_lat  merch_long  \n",
      "0          Psychologist, counselling  36.011293  -82.048315  \n",
      "1  Special educational needs teacher  49.159047 -118.186462  \n",
      "2        Nature conservation officer  43.150704 -112.154481  \n",
      "3                    Patent attorney  47.034331 -112.561071  \n",
      "4     Dance movement psychotherapist  38.674999  -78.632459  \n",
      "\n",
      "Test data preview after removing irrelevant columns:\n",
      "                               merchant        category    amt gender  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86      M   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84      F   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28      F   \n",
      "3                     fraud_Haley Group        misc_pos  60.05      M   \n",
      "4                 fraud_Johnston-Casper          travel   3.19      M   \n",
      "\n",
      "         city state    zip      lat      long  city_pop  \\\n",
      "0    Columbia    SC  29209  33.9659  -80.9355    333497   \n",
      "1     Altonah    UT  84002  40.3207 -110.4360       302   \n",
      "2    Bellmore    NY  11710  40.6729  -73.5365     34496   \n",
      "3  Titusville    FL  32780  28.5697  -80.8191     54767   \n",
      "4    Falmouth    MI  49632  44.2529  -85.0170      1126   \n",
      "\n",
      "                      job  merch_lat  merch_long  \n",
      "0     Mechanical engineer  33.986391  -81.200714  \n",
      "1  Sales professional, IT  39.450498 -109.960431  \n",
      "2       Librarian, public  40.495810  -74.196111  \n",
      "3            Set designer  28.812398  -80.883061  \n",
      "4      Furniture designer  44.959148  -85.884734  \n"
     ]
    }
   ],
   "source": [
    "# Display a preview of the datasets\n",
    "print(\"Training data preview after removing irrelevant columns:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nTest data preview after removing irrelevant columns:\")\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   merchant    1296675 non-null  object \n",
      " 1   category    1296675 non-null  object \n",
      " 2   amt         1296675 non-null  float64\n",
      " 3   gender      1296675 non-null  object \n",
      " 4   city        1296675 non-null  object \n",
      " 5   state       1296675 non-null  object \n",
      " 6   zip         1296675 non-null  int64  \n",
      " 7   lat         1296675 non-null  float64\n",
      " 8   long        1296675 non-null  float64\n",
      " 9   city_pop    1296675 non-null  int64  \n",
      " 10  job         1296675 non-null  object \n",
      " 11  merch_lat   1296675 non-null  float64\n",
      " 12  merch_long  1296675 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 128.6+ MB\n",
      "\n",
      "Test data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   merchant    555719 non-null  object \n",
      " 1   category    555719 non-null  object \n",
      " 2   amt         555719 non-null  float64\n",
      " 3   gender      555719 non-null  object \n",
      " 4   city        555719 non-null  object \n",
      " 5   state       555719 non-null  object \n",
      " 6   zip         555719 non-null  int64  \n",
      " 7   lat         555719 non-null  float64\n",
      " 8   long        555719 non-null  float64\n",
      " 9   city_pop    555719 non-null  int64  \n",
      " 10  job         555719 non-null  object \n",
      " 11  merch_lat   555719 non-null  float64\n",
      " 12  merch_long  555719 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 55.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the datasets\n",
    "print(\"Training data information:\")\n",
    "X_train.info()\n",
    "\n",
    "print(\"\\nTest data information:\")\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QLo3QbYh6hy1"
   },
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X_train.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Lrw2z1ro6jwY"
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing and training pipeline function\n",
    "def create_pipeline(model):\n",
    "    return Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=3000),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Logistic Regression trained and evaluated successfully.\n",
      "Model Decision Tree trained and evaluated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    pipeline = create_pipeline(model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate the model\n",
    "    results[model_name] = {\n",
    "        'classification_report': classification_report(y_test, y_pred),\n",
    "        'roc_auc_score': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    print(f\"Model {model_name} trained and evaluated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.01      0.00      0.00      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.50      0.50      0.50    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n",
      "ROC-AUC Score: 0.6171699025875703\n",
      "\n",
      "Model: Decision Tree\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.59      0.57      0.58      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.79      0.78      0.79    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "ROC-AUC Score: 0.7831537648765337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(result['classification_report'])\n",
    "    print(f\"ROC-AUC Score: {result['roc_auc_score']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
